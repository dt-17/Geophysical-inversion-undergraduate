{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ACSE-7 (Optimisation & Inversion) <a class=\"tocSkip\">\n",
    "\n",
    "## Lecture 5 <a class=\"tocSkip\">\n",
    "    \n",
    "### Homework Exercises <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Homework\" data-toc-modified-id=\"Homework-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Homework</a></span><ul class=\"toc-item\"><li><span><a href=\"#Homework---Transformation-of-the-unit-circle---the-case-of-symmetric-matrix\" data-toc-modified-id=\"Homework---Transformation-of-the-unit-circle---the-case-of-symmetric-matrix-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Homework - Transformation of the unit circle - the case of symmetric matrix</a></span></li><li><span><a href=\"#Homework---Eigenvector-example\" data-toc-modified-id=\"Homework---Eigenvector-example-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Homework - Eigenvector example</a></span></li><li><span><a href=\"#Homework---Matrix-diagonalisation\" data-toc-modified-id=\"Homework---Matrix-diagonalisation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Homework - Matrix diagonalisation</a></span></li><li><span><a href=\"#Homework---Transformation-using-the-diagonalisation-matrices-in-turn\" data-toc-modified-id=\"Homework---Transformation-using-the-diagonalisation-matrices-in-turn-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Homework - Transformation using the diagonalisation matrices in turn</a></span></li><li><span><a href=\"#Homework---SVD-example\" data-toc-modified-id=\"Homework---SVD-example-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Homework - SVD example</a></span></li><li><span><a href=\"#Homework---Transformation-of-a-non-square-matrix-via-the-SVD-decomposition\" data-toc-modified-id=\"Homework---Transformation-of-a-non-square-matrix-via-the-SVD-decomposition-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Homework - Transformation of a non-square matrix via the SVD decomposition</a></span></li><li><span><a href=\"#Homework---When-does-the-SVD-agree-with-the-eigendecomposition\" data-toc-modified-id=\"Homework---When-does-the-SVD-agree-with-the-eigendecomposition-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Homework - When does the SVD agree with the eigendecomposition</a></span></li><li><span><a href=\"#Homework---A-least-square-and-minimum-norm-solution-to-a-simple-$2\\times-2$-case-[revisited]\" data-toc-modified-id=\"Homework---A-least-square-and-minimum-norm-solution-to-a-simple-$2\\times-2$-case-[revisited]-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Homework - A least square and minimum norm solution to a simple $2\\times 2$ case [revisited]</a></span></li><li><span><a href=\"#Homework---A-simple-mixed-determined-solution-[revisited]\" data-toc-modified-id=\"Homework---A-simple-mixed-determined-solution-[revisited]-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Homework - A simple mixed determined solution [revisited]</a></span></li><li><span><a href=\"#Homework---Tomography-example-revisited\" data-toc-modified-id=\"Homework---Tomography-example-revisited-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Homework - Tomography example revisited</a></span></li><li><span><a href=\"#Homework---Damped-least-squares\" data-toc-modified-id=\"Homework---Damped-least-squares-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>Homework - Damped least squares</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as sl\n",
    "from pprint import pprint\n",
    "import scipy.interpolate as si\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Transformation of the unit circle - the case of symmetric matrix\n",
    "\n",
    "If you recreate the transformation of the unit circle plot from the lecture in the case of a symmetric matrix, what do you notice about the \"special directions\"?\n",
    "\n",
    "In my solution I considered the case\n",
    "\n",
    "$$ A = \n",
    "\\left(\n",
    "  \\begin{array}{rr}\n",
    "    3.6 & 1.6 \\\\\n",
    "    1.6 & 3.2  \n",
    "  \\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "as it gives a nice ellipse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Eigenvector example\n",
    "\n",
    "For the matrix from class\n",
    "\n",
    "$$ A = \n",
    "\\left(\n",
    "  \\begin{array}{rr}\n",
    "    3 & 1 \\\\\n",
    "    1 & 3  \n",
    "  \\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "we worked out the eigenvalues \n",
    "\n",
    "$$\\lambda_1 = 4\\quad\\text{and}\\quad \\lambda_2 = 2$$\n",
    "\n",
    "we worked out the normalised eigenvector corresponding to the first eigenvalue as \n",
    "\n",
    "$$\\boldsymbol{v}_1 =   \n",
    "\\left(\n",
    "  \\begin{array}{r}\n",
    "    \\frac{1}{\\sqrt{2}} \\\\\n",
    "    \\frac{1}{\\sqrt{2}}  \n",
    "  \\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Work out the second eigenvector, and can you spot a relationship with the first?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Matrix diagonalisation\n",
    "\n",
    "Consider the matrix from the previous exercise and the eigenvalues and eigenvectors we found,\n",
    "construct the $P$ and $\\Lambda$ matrices and check that they can be used to form a matrix diagonalisation/decomposition that is indeed equal to $A$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Transformation using the diagonalisation matrices in turn\n",
    "\n",
    "Repeat the steps \n",
    "\n",
    "\\begin{align*}\n",
    "A\\boldsymbol{x} = P \\Lambda P^{-1}\\boldsymbol{x} = P \\; (\\Lambda\\;  (P^{-1}\\boldsymbol{x}))\n",
    "\\end{align*}\n",
    "\n",
    "geometrically starting for a unit circle using the symmetric example from Q1.\n",
    "\n",
    "Confirm what was said in the lecture: \"Now in the case of a symmetric matrix the $P$ and thus $P^{-1}$ being orthogonal matrices means that they just correspond to simple rotations - see homework.\"\n",
    "\n",
    "NB. you can just use `sl.eig` to find the eigenvalues and eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - SVD example\n",
    "\n",
    "Consider the matrix\n",
    "\n",
    "$$A = \\begin{pmatrix} \n",
    "3 & 1 & 9 & 4 \\\\\n",
    "2 & 1 & 7 & 3 \\\\\n",
    "5 & 2 & 16 & 7 \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Check that \n",
    "\n",
    "$$A = U\\Sigma V^{T}$$\n",
    "\n",
    "using the definitions of the matrices in terms of eigenvalues and eigenvectors of $AA^T$ and $A^TA$.\n",
    "\n",
    "Note that we need to choose the signs of our left and right singular vectors consistently - an issue arises if we compute these as the eigenvectors of  $AA^T$ and $A^TA$ separately. If you get an SVD that doesn't result in $A$ it might well be that you have a sign inconsistency, for more on this see <https://math.stackexchange.com/questions/2359992/how-to-resolve-the-sign-issue-in-a-svd-problem>.\n",
    "\n",
    "You can check the signs of your columns of $U$ and $V$ against the SciPy solution, and if needed flip the signs of he appropriate columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Transformation of a non-square matrix via the SVD decomposition\n",
    "\n",
    "Consider the following matrix we saw in L3 as an example of an over-determined problem\n",
    "\n",
    "$$\n",
    "  \\begin{pmatrix}\n",
    "    2 & 3 \\\\\n",
    "    1 & -4  \\\\\n",
    "    -3 & -10 \n",
    "  \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "This matrix maps $\\mathbb{R}^2$ into $\\mathbb{R}^3$.\n",
    "\n",
    "As was done in the lecture and above for a square $2\\times 2$ case, visualise each three multiplications by the matrices making up the SVD acting in the unit circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - When does the SVD agree with the eigendecomposition\n",
    "\n",
    "Consider a square matrix - check whether the SVD and the eigendecompositions agree. \n",
    "\n",
    "Compare the cases of a symmetric matrix and a non-symmetrix matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - A least square and minimum norm solution to a simple $2\\times 2$ case [revisited]\n",
    "\n",
    "In the L4 homework we considered the case \n",
    "\n",
    "$$\n",
    "\\left(\n",
    "  \\begin{array}{rr}\n",
    "    2 & 3 \\\\\n",
    "    4 & 6 \n",
    "  \\end{array}\n",
    "\\right)\\left(\n",
    "  \\begin{array}{c}\n",
    "    x \\\\\n",
    "    y\n",
    "  \\end{array}\n",
    "\\right) = \\left(\n",
    "  \\begin{array}{c}\n",
    "    4 \\\\\n",
    "    7\n",
    "  \\end{array}\n",
    "\\right),\n",
    "$$\n",
    "\n",
    "and we establised a solution that was both a least squares and a minimum norm solution.\n",
    "\n",
    "Check that we get the same result using the generatlised inverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - A simple mixed determined solution [revisited]\n",
    "\n",
    "In L4 we considered the problem\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 2 & 2 \\\\\n",
    "0 & 3 & 3\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "m_1\\\\\n",
    "m_2\\\\\n",
    "m_3\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1\\\\\n",
    "2\\\\\n",
    "2\\\\\n",
    "3\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "and came up with the solution\n",
    "\n",
    "$$\\boldsymbol{m} = \\left(\\frac{3}{2} \\;\\; \\frac{1}{2} \\;\\; \\frac{1}{2} \\right)^T.$$\n",
    "\n",
    "Do you get this solution if you use what we now know about the generalised inverse approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Tomography example revisited\n",
    "\n",
    "Recall the tomography example from the L4 homework exercises.\n",
    "\n",
    "We had the mixed determined linear system\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots  \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "\\vdots \\\\\n",
    "x_9\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "T_1\\\\\n",
    "T_2\\\\\n",
    "\\vdots \\\\\n",
    "T_6\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "for which both  $G^TG$ and $GG^T$ are singular matrices.\n",
    "\n",
    "You were asked to compute the rank of $G$ and to find a basis for the null space.\n",
    "\n",
    "We found that in the case of perfect data, $T_i=6\\; \\forall i$, that\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "2 & 2 & 2 \\\\\n",
    "2 & 2 & 2 \\\\\n",
    "2 & 2 & 2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "is a possible solution, but that the addition of any linear combination of the solutions making up a basis for the null space\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & -1 & 0 \\\\\n",
    "-1 & 1 & 0 \\\\\n",
    "0 & 0 & 0 \n",
    "\\end{pmatrix},\\quad\n",
    "\\begin{pmatrix}\n",
    "0 & 1 & -1 \\\\\n",
    "0 & -1 & 1 \\\\\n",
    "0 & 0 & 0 \n",
    "\\end{pmatrix},\\quad\n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 1 & -1 \\\\\n",
    "0 & -1 & 1 \n",
    "\\end{pmatrix},\\quad\n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "1 & -1 & 0 \\\\\n",
    "-1 & 1 & 0 \n",
    "\\end{pmatrix}\n",
    "$$ \n",
    "\n",
    "also yields equally valid solutions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imperfect data**\n",
    "\n",
    "In L4 we introduced the concept of the data potentially containing errors, i.e. if instead of all data values being 6, consider the case with\n",
    "\n",
    "$$ \\boldsymbol{T} = (6.07, 6.07, 5.77, 5.93, 5.93, 6.03)^T $$\n",
    "\n",
    "We stated tht now, even though there are fewer data than model parameters, there is no model that fits the  data exactly.  We can see this because it should be the case from $G$ that\n",
    "\n",
    "$$ T_1  + T_2  + T_3  = T_4  + T_5  + T_6$$  \n",
    "\n",
    "whereas for this data\n",
    "\n",
    "$$ T_1 + T_2  + T_3  = 17.91, \\qquad T_4 + T_5  + T_6  = 17.89 $$\n",
    "\n",
    "so that, with these data, there can be no solution. \n",
    "\n",
    "<br><br>\n",
    "\n",
    "**How to proceed?**\n",
    "\n",
    "This is what we stated:\n",
    "\n",
    "In  this  problem,  $G$  is  not  square  so  that  $G^{-1}$ does  not  exist,  and  both  $G^TG$ and $GG^T$ are singular matrices, so that none of the methods that we have used so far will work.  \n",
    "\n",
    "How then can we proceed?   \n",
    "\n",
    "There are two principal options: \n",
    "\n",
    "\n",
    "1. we can use the generalised inverse $G^+$, also known as the pseudo-inverse or the [Moore-Penrose inverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse), or\n",
    "\n",
    "\n",
    "2. we can use some form of regularisation to the model of which damped least-squares is the most straightforward.   \n",
    "\n",
    "\n",
    "The generalised inverse is  preferable in  small problems, especially  when we would like to analyse the quality of the results carefully, while regularised least-squares and related methods are preferable for large problems when the generalised inverse is prohibitively expensive, or when linearised inversion is being used in order to solve a non-linear problem by iteration. \n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Use the generalised inverse computed via the SVD (compare it against the inverse computed using `np.linalg.pinv`) to compute the solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Damped least squares\n",
    "\n",
    "Consider again the tolography example from the previous exercise with noisy data.\n",
    "\n",
    "Now try solving this problem using the damped least squares approach and show that as $\\mu$ tends to zero we recover the same solution as found in the previous question using the generalised inverse."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
